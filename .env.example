# AI Model Configuration
# Choose your AI provider: "ollama" (local), "openai", or "anthropic"
AI_PROVIDER=ollama

# Ollama Configuration (for local open-source models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# OpenAI Configuration (optional)
# OPENAI_API_KEY=your_openai_api_key
# OPENAI_MODEL=gpt-4-turbo-preview

# Anthropic Configuration (optional)
# ANTHROPIC_API_KEY=your_anthropic_api_key
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Documentation Sources
SUSE_DOCS_BASE_URL=https://documentation.suse.com
RANCHER_DOCS_URL=https://ranchermanager.docs.rancher.com
K3S_DOCS_URL=https://docs.k3s.io

# Vector Database Configuration
VECTOR_DB_PATH=./data/vectors
EMBEDDING_MODEL=nomic-embed-text

# Server Configuration
MCP_SERVER_NAME=docs-navigator-suse
LOG_LEVEL=info
